{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"LEARNING_RATE=5e-5\nEPOCHS=3\nBATCH_SIZE=16\n\nMAX_INPUT_LENGTH=400\nMAX_CONTEXT_LENGTH=350","metadata":{"id":"wmeMeTrXUqvn","execution":{"iopub.status.busy":"2022-03-12T12:46:12.283478Z","iopub.execute_input":"2022-03-12T12:46:12.284136Z","iopub.status.idle":"2022-03-12T12:46:12.316806Z","shell.execute_reply.started":"2022-03-12T12:46:12.284025Z","shell.execute_reply":"2022-03-12T12:46:12.316140Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"TRAIN_SET_PATH = '../input/squad-20/train-v2.0.json'\nDEV_SET_PATH = '../input/squad-20/dev-v2.0.json'","metadata":{"execution":{"iopub.status.busy":"2022-03-12T12:46:12.319611Z","iopub.execute_input":"2022-03-12T12:46:12.320177Z","iopub.status.idle":"2022-03-12T12:46:12.323344Z","shell.execute_reply.started":"2022-03-12T12:46:12.320135Z","shell.execute_reply":"2022-03-12T12:46:12.322701Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import json\nfrom typing import List, Tuple, Iterable\nfrom numbers import Number\n\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom torch.optim import Optimizer, Adam\n\nfrom transformers import BertTokenizer, BertForQuestionAnswering\nfrom transformers.tokenization_utils_base import PaddingStrategy, TruncationStrategy","metadata":{"id":"UzYM4_DLLGtD","execution":{"iopub.status.busy":"2022-03-12T12:46:12.324501Z","iopub.execute_input":"2022-03-12T12:46:12.325222Z","iopub.status.idle":"2022-03-12T12:46:14.276074Z","shell.execute_reply.started":"2022-03-12T12:46:12.325185Z","shell.execute_reply":"2022-03-12T12:46:14.275311Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"CPU_DEVICE = 'cpu'\nCUDA_DEVICE = 'cuda'\nDEVICE = CUDA_DEVICE if torch.cuda.is_available() else CPU_DEVICE","metadata":{"id":"hkVdzsJK_Lje","execution":{"iopub.status.busy":"2022-03-12T12:46:14.281323Z","iopub.execute_input":"2022-03-12T12:46:14.283605Z","iopub.status.idle":"2022-03-12T12:46:14.337121Z","shell.execute_reply.started":"2022-03-12T12:46:14.283561Z","shell.execute_reply":"2022-03-12T12:46:14.336416Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"NO_ANSWER = (0, 0)\n\nclass QuestionContext:\n    \"\"\" Represents a SQuAD Context, along with any useful information. \"\"\"\n    def __init__(self, text, tokenizer) -> None:\n        self.text = text\n        self.tokenIds = tokenizer(text, truncation=True, max_length=MAX_CONTEXT_LENGTH)['input_ids']\n        self.tokens = tokenizer.convert_ids_to_tokens(self.tokenIds)\n        whitespaces = []\n        for i, c in enumerate(text):\n            if c == ' ':\n                whitespaces.append(i)\n        \n        self.whitespaces = tuple(whitespaces)\n\n    def getAnswerTokenIndexes(self, startCharIndex, endCharIndex):\n        \"\"\" Maps the given character indexes to context token indexes. \"\"\"\n        answerStart = -1\n        answerEnd = -1\n        currChar = 0\n        for index, token in enumerate(self.tokens):\n            if (index != 0) and (index != len(self.tokens) - 1):\n                cleanToken = token.replace('##', '')\n                for c in cleanToken:\n                    if currChar == startCharIndex:\n                        answerStart = index\n                    if currChar == endCharIndex:\n                        answerEnd = index\n                        return (answerStart, answerEnd)\n                    currChar += 1\n        return NO_ANSWER\n\nclass Question:\n    \"\"\" Represents a SQuAD Question, along with any useful information. \"\"\"\n    def __init__(self, text: str, answer: Dict[str, int], context: QuestionContext, isImpossible = False) -> None:\n        # Original question text\n        self.text = text\n        # Reference to the QuestionContext object\n        self.context = context\n        \n        # Storing the answer start and end token indexes\n        if isImpossible:\n            self.answer = NO_ANSWER\n        else:\n            endCharIndex = answer['answer_start'] + len(answer['text']) - 1\n            whitespacesBeforeAnswer = 0\n            whitespacesInAnswer = 0\n            for i in context.whitespaces:\n                if i >= answer['answer_start']:\n                    if i < endCharIndex:\n                        whitespacesInAnswer += 1\n                    else:\n                        break\n                else:\n                    whitespacesBeforeAnswer += 1\n            noWhitespaceStart = answer['answer_start'] - whitespacesBeforeAnswer\n            noWhitespaceEnd = noWhitespaceStart + len(answer['text']) - 1 - whitespacesInAnswer\n            self.answer = context.getAnswerTokenIndexes(noWhitespaceStart, noWhitespaceEnd)\n\n    def __repr__(self) -> str:\n        if self.answer == NO_ANSWER:            \n            answer = ' '.join(self.context.tokens[self.answer[0]:self.answer[1]+1])\n        else:\n            answer = ''\n        return str({\n            \"text\": self.text,\n            \"answer_start\": self.answer[0],\n            \"answer_end\": self.answer[1],\n            \"answer\": answer\n        })","metadata":{"id":"QTAGsLf0ZnH4","execution":{"iopub.status.busy":"2022-03-12T12:46:14.341901Z","iopub.execute_input":"2022-03-12T12:46:14.344321Z","iopub.status.idle":"2022-03-12T12:46:14.368571Z","shell.execute_reply.started":"2022-03-12T12:46:14.344283Z","shell.execute_reply":"2022-03-12T12:46:14.367688Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\ndef readDataset(path: str, limit=None) -> List[Question]:\n    # Question objects will be stored here\n    questions = []\n    with open(path) as samplesFile:\n        samplesRaw = json.load(samplesFile)['data']\n        for group in samplesRaw:\n            for paragraph in group['paragraphs']:\n                context = QuestionContext(paragraph['context'], tokenizer)\n                for qa in paragraph['qas']:\n                    answer = qa['answers'][0] if not qa['is_impossible'] else None\n                    questions.append(Question(qa['question'], answer, context, qa['is_impossible']))\n                    if limit and len(questions) >= limit:\n                        return questions\n\n    return questions","metadata":{"id":"W_2J2jMaLj5B","outputId":"67a355b4-7e25-49f9-cb10-acd5ec827f71","execution":{"iopub.status.busy":"2022-03-12T12:46:14.372598Z","iopub.execute_input":"2022-03-12T12:46:14.374706Z","iopub.status.idle":"2022-03-12T12:46:22.572963Z","shell.execute_reply.started":"2022-03-12T12:46:14.374668Z","shell.execute_reply":"2022-03-12T12:46:22.572150Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c702e6ab2a3480aa08648841f2aa2ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"795261e746e0472fa32c50675b3ffcf6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de449c976ea24ab6b729c106d531f47e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c471af01b6df425196dd12a30cf75f46"}},"metadata":{}}]},{"cell_type":"code","source":"class QuestionsDataset(torch.utils.data.Dataset):\n    def __init__(self, questions: List[Question]) -> None:\n        super().__init__()\n        self.questions = [q.text for q in questions]\n        self.contexts = [q.context.text for q in questions]\n        self.answers = [torch.tensor(q.answer) for q in questions]\n\n    def __len__(self):\n        return len(self.questions)\n\n    def __getitem__(self, index: int):\n        return self.questions[index], self.contexts[index], self.answers[index]","metadata":{"id":"E7Rs6zeENvJk","execution":{"iopub.status.busy":"2022-03-12T12:46:22.574108Z","iopub.execute_input":"2022-03-12T12:46:22.574431Z","iopub.status.idle":"2022-03-12T12:46:22.582035Z","shell.execute_reply.started":"2022-03-12T12:46:22.574392Z","shell.execute_reply":"2022-03-12T12:46:22.580275Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def predictionsF1Score(modelAnswers: Iterable[Tuple[int]], trueAnswers: Iterable[Tuple[int]]) -> Number:\n\n    def findAnswerF1(modelAnswer: Tuple[int], trueAnswer: Tuple[int]) -> Number:\n        modelSequence = range(modelAnswer[0], modelAnswer[1] + 1 )\n        trueSequence = range(trueAnswer[0], trueAnswer[1] + 1 )\n        numCommon = len(set(trueSequence).intersection(modelSequence))\n\n        if numCommon == 0:\n            return 0\n        \n        precision = 1.0 * numCommon / len(trueSequence)\n        recall = 1.0 * numCommon / len(modelSequence)\n        f1 = (2 * precision * recall) / (precision + recall)\n        return f1\n\n    totalF1 = 0\n    for model, gold in zip(modelAnswers, trueAnswers):\n        totalF1 += findAnswerF1(model, gold)\n\n    return totalF1/len(trueAnswers)\n\ndef predictionsExactScore(modelAnswers: Iterable[Tuple[int]], trueAnswers: Iterable[Tuple[int]]) -> Number:\n    correct = 0\n    for model, true in zip(modelAnswers, trueAnswers):\n        correct += int( (model[0] == true[0]) and (model[1] == true[1]) )\n    \n    return correct/len(trueAnswers)\n\ndef getPredictedAnswers(startLogits: torch.Tensor, endLogits: torch.Tensor) -> Tuple[np.ndarray, np.ndarray]:\n    softmaxStart = torch.log_softmax(startLogits, dim = 1)\n    _, start = torch.max(softmaxStart, dim = 1)\n\n    softmaxEnd = torch.log_softmax(endLogits, dim = 1)\n    _, end = torch.max(softmaxEnd, dim = 1)\n    return (start.cpu().detach().numpy(), end.cpu().detach().numpy())","metadata":{"id":"qZw2MOKoVj-1","execution":{"iopub.status.busy":"2022-03-12T12:46:22.583756Z","iopub.execute_input":"2022-03-12T12:46:22.584418Z","iopub.status.idle":"2022-03-12T12:46:22.596112Z","shell.execute_reply.started":"2022-03-12T12:46:22.584378Z","shell.execute_reply":"2022-03-12T12:46:22.595380Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def trainModel(model: BertForQuestionAnswering, optimizer: Optimizer, tokenizer: BertTokenizer,\n               trainSetLoader: DataLoader, devSetLoader: DataLoader) -> None:\n    for epoch in range(EPOCHS):\n        trainExactScores = []\n        trainLosses = []\n        trainF1 = []\n        devExactScores = []\n        devLosses = []\n        devF1 = []\n        \n        model.train()        \n        for batchQuestions, batchContexts, batchAnswers in trainSetLoader:\n            qaPairs = [[question, answer] for question, answer in zip(batchQuestions, batchContexts)]\n            tok = tokenizer._batch_encode_plus( qaPairs,\n                                                truncation_strategy=TruncationStrategy.ONLY_SECOND,\n                                                max_length=MAX_INPUT_LENGTH,\n                                                padding_strategy=PaddingStrategy.MAX_LENGTH,\n                                                return_tensors=\"pt\")\n            inputIds = tok['input_ids'].to(DEVICE)\n            segmentIds = tok['token_type_ids'].to(DEVICE)\n            attentionMask = tok['attention_mask'].to(DEVICE)\n            startPositions = batchAnswers[:, 0].to(DEVICE)\n            endPositions = batchAnswers[:, 1].to(DEVICE)\n\n            outputs = model(input_ids=inputIds, token_type_ids=segmentIds, attention_mask=attentionMask, start_positions=startPositions, end_positions=endPositions)    \n\n            optimizer.zero_grad()\n\n            outputs.loss.backward()\n\n            optimizer.step()\n\n            startPredictions, endPredictions = getPredictedAnswers(outputs.start_logits, outputs.end_logits)\n            modelAnswers = np.vstack((startPredictions, endPredictions)).T\n\n            trainExactScores.append(predictionsExactScore(modelAnswers, batchAnswers))\n            trainLosses.append(outputs.loss.item())\n            trainF1.append(predictionsF1Score(modelAnswers, batchAnswers))\n            \n        model.eval()\n        with torch.no_grad():\n            for batchQuestions, batchContexts, batchAnswers in devSetLoader:\n                qaPairs = [[question, answer] for question, answer in zip(batchQuestions, batchContexts)]\n                tok = tokenizer._batch_encode_plus( qaPairs,\n                                                    truncation_strategy=TruncationStrategy.ONLY_SECOND,\n                                                    max_length=MAX_INPUT_LENGTH,\n                                                    padding_strategy=PaddingStrategy.MAX_LENGTH,\n                                                    return_tensors=\"pt\")                \n                inputIds = tok['input_ids'].to(DEVICE)\n                segmentIds = tok['token_type_ids'].to(DEVICE)\n                attentionMask = tok['attention_mask'].to(DEVICE)\n                startPositions = batchAnswers[:, 0].to(DEVICE)\n                endPositions = batchAnswers[:, 1].to(DEVICE)\n                \n                outputs = model(input_ids=inputIds, token_type_ids=segmentIds,\n                                attention_mask=attentionMask,\n                                start_positions=startPositions, end_positions=endPositions)\n                \n                startPredictions, endPredictions = getPredictedAnswers(outputs.start_logits, outputs.end_logits)\n                modelAnswers = np.vstack((startPredictions, endPredictions)).T\n\n                devExactScores.append(predictionsExactScore(modelAnswers, batchAnswers))\n                devLosses.append(outputs.loss.item())\n                devF1.append(predictionsF1Score(modelAnswers, batchAnswers))\n\n        print(f\"################ EPOCH {epoch} ################\")\n        print(\"--------------- Train Set ---------------\")\n        print(f\"Exact: {sum(trainExactScores)/len(trainExactScores):.5f}\", end=' ')\n        print(f\"F1: {sum(trainF1)/len(trainF1):.5f}\", end=' ')\n        print(f\"Loss: {sum(trainLosses)/len(trainLosses):.5f}\")\n        print(\"------------- Validation Set ------------\")\n        print(f\"Exact: {sum(devExactScores)/len(devExactScores):.5f}\", end=' ')\n        print(f\"F1: {sum(devF1)/len(devF1):.5f}\", end=' ')\n        print(f\"Loss: {sum(devLosses)/len(devLosses):.5f}\")","metadata":{"id":"EsL_ERhbVUIN","execution":{"iopub.status.busy":"2022-03-12T12:46:22.597497Z","iopub.execute_input":"2022-03-12T12:46:22.597752Z","iopub.status.idle":"2022-03-12T12:46:22.616366Z","shell.execute_reply.started":"2022-03-12T12:46:22.597719Z","shell.execute_reply":"2022-03-12T12:46:22.615549Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"trainQuestions = readDataset(TRAIN_SET_PATH)\ndevQuestions = readDataset(DEV_SET_PATH)\n\ntrainSetLoader = DataLoader(QuestionsDataset(trainQuestions), batch_size=BATCH_SIZE, shuffle=False)\ndevSetLoader = DataLoader(QuestionsDataset(devQuestions), batch_size=BATCH_SIZE, shuffle=False)\n\nmodel = BertForQuestionAnswering.from_pretrained('bert-base-uncased').to(DEVICE)\noptimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)","metadata":{"id":"ZoxQAYdROoKE","outputId":"84a6fa18-5fe8-4a38-b210-a1be36a937d4","execution":{"iopub.status.busy":"2022-03-12T12:46:22.618610Z","iopub.execute_input":"2022-03-12T12:46:22.619287Z","iopub.status.idle":"2022-03-12T12:48:20.492282Z","shell.execute_reply.started":"2022-03-12T12:46:22.619252Z","shell.execute_reply":"2022-03-12T12:48:20.491514Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45bbb56b5fbc4f14bf2477afd7a61df7"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForQuestionAnswering: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"trainModel(model, optimizer, tokenizer, trainSetLoader, devSetLoader)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T12:48:20.493423Z","iopub.execute_input":"2022-03-12T12:48:20.495300Z","iopub.status.idle":"2022-03-12T17:58:02.085919Z","shell.execute_reply.started":"2022-03-12T12:48:20.495261Z","shell.execute_reply":"2022-03-12T17:58:02.085138Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"################ EPOCH 0 ################\n--------------- Train Set ---------------\nExact: 0.31143 F1: 0.40548 Loss: 2.53840\n------------- Validation Set ------------\nExact: 0.50370 F1: 0.50729 Loss: 3.04705\n################ EPOCH 1 ################\n--------------- Train Set ---------------\nExact: 0.37730 F1: 0.56004 Loss: 1.72892\n------------- Validation Set ------------\nExact: 0.47847 F1: 0.52476 Loss: 2.53046\n################ EPOCH 2 ################\n--------------- Train Set ---------------\nExact: 0.46819 F1: 0.66572 Loss: 1.31908\n------------- Validation Set ------------\nExact: 0.47889 F1: 0.54342 Loss: 2.71112\n","output_type":"stream"}]}]}