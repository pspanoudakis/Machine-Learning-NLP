{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La9R9SfiKrAP"
      },
      "source": [
        "# Fine-tuning `BertForQuestionAnswering` on SQuAD 2.0\n",
        "Pavlos Spanoudakis (sdi1800184)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q65UWckPKrAS"
      },
      "source": [
        "Colab does not have `transformers` pre-installed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wh-dMx_KrAT",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4qvz1ZRKrAT"
      },
      "source": [
        "### Setting up hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-12T23:59:10.735172Z",
          "iopub.status.busy": "2022-03-12T23:59:10.734487Z",
          "iopub.status.idle": "2022-03-12T23:59:10.740585Z",
          "shell.execute_reply": "2022-03-12T23:59:10.739153Z",
          "shell.execute_reply.started": "2022-03-12T23:59:10.735129Z"
        },
        "id": "wmeMeTrXUqvn",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "LEARNING_RATE=5e-5\n",
        "EPOCHS=3\n",
        "BATCH_SIZE=16\n",
        "\n",
        "MAX_INPUT_LENGTH=400\n",
        "MAX_CONTEXT_LENGTH=350"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWG_-anaKrAU"
      },
      "source": [
        "### Setting up Dataset paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-12T23:59:10.742936Z",
          "iopub.status.busy": "2022-03-12T23:59:10.742019Z",
          "iopub.status.idle": "2022-03-12T23:59:10.751411Z",
          "shell.execute_reply": "2022-03-12T23:59:10.750483Z",
          "shell.execute_reply.started": "2022-03-12T23:59:10.742895Z"
        },
        "id": "xlt35n50KrAU",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "TRAIN_SET_PATH = '../input/squad-20/train-v2.0.json'\n",
        "DEV_SET_PATH = '../input/squad-20/dev-v2.0.json'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJdSBxogKrAU"
      },
      "source": [
        "### Necessary Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-12T23:59:10.754311Z",
          "iopub.status.busy": "2022-03-12T23:59:10.753747Z",
          "iopub.status.idle": "2022-03-12T23:59:12.639630Z",
          "shell.execute_reply": "2022-03-12T23:59:12.638890Z",
          "shell.execute_reply.started": "2022-03-12T23:59:10.754277Z"
        },
        "id": "UzYM4_DLLGtD",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from typing import List, Dict, Tuple, Iterable\n",
        "from numbers import Number\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Optimizer, Adam\n",
        "\n",
        "from transformers import BertTokenizer, BertForQuestionAnswering\n",
        "from transformers.tokenization_utils_base import PaddingStrategy, TruncationStrategy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MaMl0y6KrAV"
      },
      "source": [
        "### Enabling GPU acceleration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-12T23:59:12.641445Z",
          "iopub.status.busy": "2022-03-12T23:59:12.641146Z",
          "iopub.status.idle": "2022-03-12T23:59:12.684859Z",
          "shell.execute_reply": "2022-03-12T23:59:12.684161Z",
          "shell.execute_reply.started": "2022-03-12T23:59:12.641404Z"
        },
        "id": "hkVdzsJK_Lje",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "CPU_DEVICE = 'cpu'\n",
        "CUDA_DEVICE = 'cuda'\n",
        "DEVICE = CUDA_DEVICE if torch.cuda.is_available() else CPU_DEVICE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgTTMn5oKrAV"
      },
      "source": [
        "### Storing context & questions information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-12T23:59:12.687975Z",
          "iopub.status.busy": "2022-03-12T23:59:12.687769Z",
          "iopub.status.idle": "2022-03-12T23:59:12.704674Z",
          "shell.execute_reply": "2022-03-12T23:59:12.703755Z",
          "shell.execute_reply.started": "2022-03-12T23:59:12.687950Z"
        },
        "id": "QTAGsLf0ZnH4",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "NO_ANSWER = (0, 0)\n",
        "\n",
        "class QuestionContext:\n",
        "    \"\"\" Represents a SQuAD Context, along with any useful information. \"\"\"\n",
        "    def __init__(self, text: str, tokenizer: BertTokenizer) -> None:\n",
        "        self.text = text\n",
        "        self.tokenIds = tokenizer(text, truncation=True, max_length=MAX_CONTEXT_LENGTH)['input_ids']\n",
        "        self.tokens = tokenizer.convert_ids_to_tokens(self.tokenIds)\n",
        "        whitespaces = []\n",
        "        for i, c in enumerate(text):\n",
        "            if c == ' ':\n",
        "                whitespaces.append(i)\n",
        "        \n",
        "        self.whitespaces = tuple(whitespaces)\n",
        "\n",
        "    def getAnswerTokenIndexes(self, startCharIndex: int, endCharIndex: int) -> Tuple[int, int]:\n",
        "        \"\"\" Maps the given character indexes to context token indexes. \"\"\"\n",
        "        answerStart = -1\n",
        "        answerEnd = -1\n",
        "        currChar = 0\n",
        "        for index, token in enumerate(self.tokens):\n",
        "            if (index != 0) and (index != len(self.tokens) - 1):\n",
        "                cleanToken = token.replace('##', '')\n",
        "                for c in cleanToken:\n",
        "                    if currChar == startCharIndex:\n",
        "                        answerStart = index\n",
        "                    if currChar == endCharIndex:\n",
        "                        answerEnd = index\n",
        "                        return (answerStart, answerEnd)\n",
        "                    currChar += 1\n",
        "        return NO_ANSWER\n",
        "\n",
        "class Question:\n",
        "    \"\"\" Represents a SQuAD Question, along with any useful information. \"\"\"\n",
        "    def __init__(self, text: str, answer: Dict[str, int], context: QuestionContext, isImpossible = False) -> None:\n",
        "        # Original question text\n",
        "        self.text = text\n",
        "        # Reference to the QuestionContext object\n",
        "        self.context = context\n",
        "        \n",
        "        # Storing the answer start and end token indexes\n",
        "        if isImpossible:\n",
        "            self.answer = NO_ANSWER\n",
        "        else:\n",
        "            endCharIndex = answer['answer_start'] + len(answer['text']) - 1\n",
        "            whitespacesBeforeAnswer = 0\n",
        "            whitespacesInAnswer = 0\n",
        "            for i in context.whitespaces:\n",
        "                if i >= answer['answer_start']:\n",
        "                    if i < endCharIndex:\n",
        "                        whitespacesInAnswer += 1\n",
        "                    else:\n",
        "                        break\n",
        "                else:\n",
        "                    whitespacesBeforeAnswer += 1\n",
        "            noWhitespaceStart = answer['answer_start'] - whitespacesBeforeAnswer\n",
        "            noWhitespaceEnd = noWhitespaceStart + len(answer['text']) - 1 - whitespacesInAnswer\n",
        "            self.answer = context.getAnswerTokenIndexes(noWhitespaceStart, noWhitespaceEnd)\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        if self.answer == NO_ANSWER:            \n",
        "            answer = ' '.join(self.context.tokens[self.answer[0]:self.answer[1]+1])\n",
        "        else:\n",
        "            answer = ''\n",
        "        return str({\n",
        "            \"text\": self.text,\n",
        "            \"answer_start\": self.answer[0],\n",
        "            \"answer_end\": self.answer[1],\n",
        "            \"answer\": answer\n",
        "        })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nC1v-ooKrAW"
      },
      "source": [
        "### Reading and storing each Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "2d0ee89288ab4c16ae6b947553487602",
            "68122a8b46714a00b6abc0a43cfbd517",
            "14c01983d7074b19a7365acdb5218134",
            "d7e69a6905d54c3998972ad466d887fc"
          ]
        },
        "execution": {
          "iopub.execute_input": "2022-03-12T23:59:12.707509Z",
          "iopub.status.busy": "2022-03-12T23:59:12.707319Z",
          "iopub.status.idle": "2022-03-12T23:59:17.527032Z",
          "shell.execute_reply": "2022-03-12T23:59:17.526395Z",
          "shell.execute_reply.started": "2022-03-12T23:59:12.707486Z"
        },
        "id": "W_2J2jMaLj5B",
        "outputId": "67a355b4-7e25-49f9-cb10-acd5ec827f71",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d0ee89288ab4c16ae6b947553487602",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "68122a8b46714a00b6abc0a43cfbd517",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "14c01983d7074b19a7365acdb5218134",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d7e69a6905d54c3998972ad466d887fc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "def readDataset(path: str, limit: int=None) -> List[Question]:\n",
        "    # Question objects will be stored here\n",
        "    questions = []\n",
        "    with open(path) as samplesFile:\n",
        "        samplesRaw = json.load(samplesFile)['data']\n",
        "        for group in samplesRaw:\n",
        "            for paragraph in group['paragraphs']:\n",
        "                context = QuestionContext(paragraph['context'], tokenizer)\n",
        "                for qa in paragraph['qas']:\n",
        "                    answer = qa['answers'][0] if not qa['is_impossible'] else None\n",
        "                    questions.append(Question(qa['question'], answer, context, qa['is_impossible']))\n",
        "                    if limit and len(questions) >= limit:\n",
        "                        return questions\n",
        "\n",
        "    return questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwccsOIbKrAX"
      },
      "source": [
        "### `Dataset` class to provide to a `DataLoader`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-12T23:59:17.528362Z",
          "iopub.status.busy": "2022-03-12T23:59:17.528088Z",
          "iopub.status.idle": "2022-03-12T23:59:17.535164Z",
          "shell.execute_reply": "2022-03-12T23:59:17.534533Z",
          "shell.execute_reply.started": "2022-03-12T23:59:17.528324Z"
        },
        "id": "E7Rs6zeENvJk",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class QuestionsDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, questions: List[Question]) -> None:\n",
        "        super().__init__()\n",
        "        self.questions = [q.text for q in questions]\n",
        "        self.contexts = [q.context.text for q in questions]\n",
        "        self.answers = [torch.tensor(q.answer) for q in questions]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.questions)\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        return self.questions[index], self.contexts[index], self.answers[index]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40HlIs_vKrAY"
      },
      "source": [
        "### Routines for metrics calculation during training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-12T23:59:17.536932Z",
          "iopub.status.busy": "2022-03-12T23:59:17.536206Z",
          "iopub.status.idle": "2022-03-12T23:59:17.550813Z",
          "shell.execute_reply": "2022-03-12T23:59:17.550094Z",
          "shell.execute_reply.started": "2022-03-12T23:59:17.536896Z"
        },
        "id": "qZw2MOKoVj-1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def predictionsF1Score(modelAnswers: Iterable[Tuple[int]], trueAnswers: Iterable[Tuple[int]]) -> Number:\n",
        "\n",
        "    def findAnswerF1(modelAnswer: Tuple[int], trueAnswer: Tuple[int]) -> Number:\n",
        "        modelSequence = range(modelAnswer[0], modelAnswer[1] + 1 )\n",
        "        trueSequence = range(trueAnswer[0], trueAnswer[1] + 1 )\n",
        "        numCommon = len(set(trueSequence).intersection(modelSequence))\n",
        "\n",
        "        if numCommon == 0:\n",
        "            return 0\n",
        "        \n",
        "        precision = 1.0 * numCommon / len(trueSequence)\n",
        "        recall = 1.0 * numCommon / len(modelSequence)\n",
        "        f1 = (2 * precision * recall) / (precision + recall)\n",
        "        return f1\n",
        "\n",
        "    totalF1 = 0\n",
        "    for model, gold in zip(modelAnswers, trueAnswers):\n",
        "        totalF1 += findAnswerF1(model, gold)\n",
        "\n",
        "    return totalF1/len(trueAnswers)\n",
        "\n",
        "def predictionsExactScore(modelAnswers: Iterable[Tuple[int]], trueAnswers: Iterable[Tuple[int]]) -> Number:\n",
        "    correct = 0\n",
        "    for model, true in zip(modelAnswers, trueAnswers):\n",
        "        correct += int( (model[0] == true[0]) and (model[1] == true[1]) )\n",
        "    \n",
        "    return correct/len(trueAnswers)\n",
        "\n",
        "def getPredictedAnswers(startLogits: torch.Tensor, endLogits: torch.Tensor) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    softmaxStart = torch.log_softmax(startLogits, dim = 1)\n",
        "    _, start = torch.max(softmaxStart, dim = 1)\n",
        "\n",
        "    softmaxEnd = torch.log_softmax(endLogits, dim = 1)\n",
        "    _, end = torch.max(softmaxEnd, dim = 1)\n",
        "    return (start.cpu().detach().numpy(), end.cpu().detach().numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-j7QY3hsKrAZ"
      },
      "source": [
        "### Training the model & displaying metrics after each epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-12T23:59:17.555238Z",
          "iopub.status.busy": "2022-03-12T23:59:17.554771Z",
          "iopub.status.idle": "2022-03-12T23:59:17.574620Z",
          "shell.execute_reply": "2022-03-12T23:59:17.573938Z",
          "shell.execute_reply.started": "2022-03-12T23:59:17.555198Z"
        },
        "id": "EsL_ERhbVUIN",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def trainModel(model: BertForQuestionAnswering, optimizer: Optimizer, tokenizer: BertTokenizer,\n",
        "               trainSetLoader: DataLoader, devSetLoader: DataLoader) -> None:\n",
        "    for epoch in range(EPOCHS):\n",
        "        trainExactScores = []\n",
        "        trainLosses = []\n",
        "        trainF1 = []\n",
        "        devExactScores = []\n",
        "        devLosses = []\n",
        "        devF1 = []\n",
        "        \n",
        "        model.train()        \n",
        "        for batchQuestions, batchContexts, batchAnswers in trainSetLoader:\n",
        "            qaPairs = [[question, answer] for question, answer in zip(batchQuestions, batchContexts)]\n",
        "            tok = tokenizer._batch_encode_plus( qaPairs,\n",
        "                                                truncation_strategy=TruncationStrategy.ONLY_SECOND,\n",
        "                                                max_length=MAX_INPUT_LENGTH,\n",
        "                                                padding_strategy=PaddingStrategy.MAX_LENGTH,\n",
        "                                                return_tensors=\"pt\")\n",
        "            inputIds = tok['input_ids'].to(DEVICE)\n",
        "            segmentIds = tok['token_type_ids'].to(DEVICE)\n",
        "            attentionMask = tok['attention_mask'].to(DEVICE)\n",
        "            startPositions = batchAnswers[:, 0].to(DEVICE)\n",
        "            endPositions = batchAnswers[:, 1].to(DEVICE)\n",
        "\n",
        "            outputs = model(input_ids=inputIds, token_type_ids=segmentIds, attention_mask=attentionMask, start_positions=startPositions, end_positions=endPositions)    \n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs.loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            startPredictions, endPredictions = getPredictedAnswers(outputs.start_logits, outputs.end_logits)\n",
        "            modelAnswers = np.vstack((startPredictions, endPredictions)).T\n",
        "\n",
        "            trainExactScores.append(predictionsExactScore(modelAnswers, batchAnswers))\n",
        "            trainLosses.append(outputs.loss.item())\n",
        "            trainF1.append(predictionsF1Score(modelAnswers, batchAnswers))\n",
        "            \n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for batchQuestions, batchContexts, batchAnswers in devSetLoader:\n",
        "                qaPairs = [[question, answer] for question, answer in zip(batchQuestions, batchContexts)]\n",
        "                tok = tokenizer._batch_encode_plus( qaPairs,\n",
        "                                                    truncation_strategy=TruncationStrategy.ONLY_SECOND,\n",
        "                                                    max_length=MAX_INPUT_LENGTH,\n",
        "                                                    padding_strategy=PaddingStrategy.MAX_LENGTH,\n",
        "                                                    return_tensors=\"pt\")                \n",
        "                inputIds = tok['input_ids'].to(DEVICE)\n",
        "                segmentIds = tok['token_type_ids'].to(DEVICE)\n",
        "                attentionMask = tok['attention_mask'].to(DEVICE)\n",
        "                startPositions = batchAnswers[:, 0].to(DEVICE)\n",
        "                endPositions = batchAnswers[:, 1].to(DEVICE)\n",
        "                \n",
        "                outputs = model(input_ids=inputIds, token_type_ids=segmentIds,\n",
        "                                attention_mask=attentionMask,\n",
        "                                start_positions=startPositions, end_positions=endPositions)\n",
        "                \n",
        "                startPredictions, endPredictions = getPredictedAnswers(outputs.start_logits, outputs.end_logits)\n",
        "                modelAnswers = np.vstack((startPredictions, endPredictions)).T\n",
        "\n",
        "                devExactScores.append(predictionsExactScore(modelAnswers, batchAnswers))\n",
        "                devLosses.append(outputs.loss.item())\n",
        "                devF1.append(predictionsF1Score(modelAnswers, batchAnswers))\n",
        "\n",
        "        print(f\"################ EPOCH {epoch} ################\")\n",
        "        print(\"--------------- Train Set ---------------\")\n",
        "        print(f\"Exact: {sum(trainExactScores)/len(trainExactScores):.5f}\", end=' ')\n",
        "        print(f\"F1: {sum(trainF1)/len(trainF1):.5f}\", end=' ')\n",
        "        print(f\"Loss: {sum(trainLosses)/len(trainLosses):.5f}\")\n",
        "        print(\"------------- Validation Set ------------\")\n",
        "        print(f\"Exact: {sum(devExactScores)/len(devExactScores):.5f}\", end=' ')\n",
        "        print(f\"F1: {sum(devF1)/len(devF1):.5f}\", end=' ')\n",
        "        print(f\"Loss: {sum(devLosses)/len(devLosses):.5f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9t632JpKrAa"
      },
      "source": [
        "## Execution Flow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "ec6dffc1a44a405dac08c8cf1671745d"
          ]
        },
        "execution": {
          "iopub.execute_input": "2022-03-12T23:59:17.576419Z",
          "iopub.status.busy": "2022-03-12T23:59:17.575973Z",
          "iopub.status.idle": "2022-03-13T00:01:17.939412Z",
          "shell.execute_reply": "2022-03-13T00:01:17.938583Z",
          "shell.execute_reply.started": "2022-03-12T23:59:17.576378Z"
        },
        "id": "ZoxQAYdROoKE",
        "outputId": "84a6fa18-5fe8-4a38-b210-a1be36a937d4",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ec6dffc1a44a405dac08c8cf1671745d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForQuestionAnswering: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "trainQuestions = readDataset(TRAIN_SET_PATH)\n",
        "devQuestions = readDataset(DEV_SET_PATH)\n",
        "\n",
        "trainSetLoader = DataLoader(QuestionsDataset(trainQuestions), batch_size=BATCH_SIZE, shuffle=False)\n",
        "devSetLoader = DataLoader(QuestionsDataset(devQuestions), batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "model = BertForQuestionAnswering.from_pretrained('bert-base-uncased').to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-13T00:01:17.945921Z",
          "iopub.status.busy": "2022-03-13T00:01:17.943955Z",
          "iopub.status.idle": "2022-03-13T05:10:08.024708Z",
          "shell.execute_reply": "2022-03-13T05:10:08.023971Z",
          "shell.execute_reply.started": "2022-03-13T00:01:17.945883Z"
        },
        "id": "wJ-KyHz7KrAa",
        "outputId": "14ad8604-7d42-45f2-febc-ae5ae41f86c7",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "################ EPOCH 0 ################\n",
            "--------------- Train Set ---------------\n",
            "Exact: 0.30985 F1: 0.39476 Loss: 2.59632\n",
            "------------- Validation Set ------------\n",
            "Exact: 0.50463 F1: 0.50680 Loss: 3.06969\n",
            "################ EPOCH 1 ################\n",
            "--------------- Train Set ---------------\n",
            "Exact: 0.37853 F1: 0.55488 Loss: 1.72829\n",
            "------------- Validation Set ------------\n",
            "Exact: 0.50698 F1: 0.54050 Loss: 2.38843\n",
            "################ EPOCH 2 ################\n",
            "--------------- Train Set ---------------\n",
            "Exact: 0.47340 F1: 0.66173 Loss: 1.31572\n",
            "------------- Validation Set ------------\n",
            "Exact: 0.52195 F1: 0.57065 Loss: 2.24974\n"
          ]
        }
      ],
      "source": [
        "trainModel(model, optimizer, tokenizer, trainSetLoader, devSetLoader)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "SQuAD-BERT-Model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
